{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "MO_GPKaibAji",
    "outputId": "e1dc802a-5a47-48cc-9295-e4605bb86bbd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-286dcffc6698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ls /gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "!ls /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CaR1PUrubPeA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  This is a hack to allow sibling import\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "from matrix_completion.mat_fact import MatrixFactorization\n",
    "from matrix_completion.utilis import test_train_split, is_split_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "B3U1bCq9bmKC",
    "outputId": "d06df611-c878-4036-f39f-e1151dea13d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INBRED</th>\n",
       "      <th>TESTER</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inbred_1071</td>\n",
       "      <td>Tester_1345</td>\n",
       "      <td>0.986544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inbred_1071</td>\n",
       "      <td>Tester_4373</td>\n",
       "      <td>1.057704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inbred_1071</td>\n",
       "      <td>Tester_4473</td>\n",
       "      <td>1.023704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inbred_1071</td>\n",
       "      <td>Tester_4541</td>\n",
       "      <td>1.014735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inbred_1071</td>\n",
       "      <td>Tester_5305</td>\n",
       "      <td>1.062727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        INBRED       TESTER      mean\n",
       "0  Inbred_1071  Tester_1345  0.986544\n",
       "1  Inbred_1071  Tester_4373  1.057704\n",
       "2  Inbred_1071  Tester_4473  1.023704\n",
       "3  Inbred_1071  Tester_4541  1.014735\n",
       "4  Inbred_1071  Tester_5305  1.062727"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_df = pd.read_csv(\"../data/input/grouped_data.csv\")\n",
    "grp_df.drop(labels=grp_df.columns[0], axis=1, inplace=True)\n",
    "grp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZeBAQe5ObmKI"
   },
   "outputs": [],
   "source": [
    "train_df = grp_df.pivot(index='INBRED', columns='TESTER', values='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZJVQ9XcbmKa"
   },
   "outputs": [],
   "source": [
    "test_, train_ = test_train_split(train_df=train_df, seed=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_fac = MatrixFactorization(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmax = 3\n",
    "\n",
    "parameters = {\n",
    "    'alphas': [10**i for i in range(-2,0)],\n",
    "    'betas': [10**i for i in range(-2,0)],\n",
    "    'lambdas': [0.1, 0.001],\n",
    "    'ks': list(range(2, kmax+1, 2))\n",
    "}\n",
    "\n",
    "bests = mat_fac.grid_search(parameters=parameters, kfold=2, iter_max=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.7264125918852397\n",
      "y=0.23596519750208478 + [0.7634398] * x\n"
     ]
    }
   ],
   "source": [
    "mat_fac.fit()\n",
    "pred = mat_fac.predict(test_)\n",
    "# plot some results\n",
    "mat_fac.plot_predicted_actual(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 0.01, 0.01, 0.1): {'mse': [0.032200955505045654, 0.03508908124561152],\n",
       "  'iter': [10, 10],\n",
       "  'mean': 0.033645018375328586,\n",
       "  'sd': 0.001444062870282932},\n",
       " (2, 0.01, 0.01, 0.001): {'mse': [0.03132077070114164, 0.03384671340604497],\n",
       "  'iter': [10, 10],\n",
       "  'mean': 0.03258374205359331,\n",
       "  'sd': 0.0012629713524516632},\n",
       " (2, 0.01, 0.1, 0.1): {'mse': [0.015875516951981784, 0.018848636056477762],\n",
       "  'iter': [10, 10],\n",
       "  'mean': 0.017362076504229773,\n",
       "  'sd': 0.0014865595522479888},\n",
       " (2, 0.01, 0.1, 0.001): {'mse': [0.02238089874429514, 0.019987023245810552],\n",
       "  'iter': [10, 10],\n",
       "  'mean': 0.021183960995052847,\n",
       "  'sd': 0.0011969377492422936},\n",
       " (2, 0.1, 0.01, 0.1): {'mse': [0.005383025215499293, 0.008173649964594064],\n",
       "  'iter': [10, 10],\n",
       "  'mean': 0.006778337590046679,\n",
       "  'sd': 0.0013953123745473854},\n",
       " (2, 0.1, 0.01, 0.001): {'mse': [0.0050565754287626, 0.007251613283439181],\n",
       "  'iter': [10, 10],\n",
       "  'mean': 0.006154094356100891,\n",
       "  'sd': 0.0010975189273382904},\n",
       " (2, 0.1, 0.1, 0.1): {'mse': [0.0029489082978754037, 0.003448049672332824],\n",
       "  'iter': [10, 10],\n",
       "  'mean': 0.003198478985104114,\n",
       "  'sd': 0.0002495706872287101},\n",
       " (2, 0.1, 0.1, 0.001): {'mse': [0.0030525765029446855, 0.003465276860435678],\n",
       "  'iter': [10, 10],\n",
       "  'mean': 0.003258926681690182,\n",
       "  'sd': 0.00020635017874549638}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_fac.best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 0.1, 0.1, 0.1): {'mean': 0.003198478985104114,\n",
       "  'sd': 0.0002495706872287101,\n",
       "  'iter': 10}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_fac.global_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(y):\n",
    "    return (y - 0.23596519750208478) / 0.7634398"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>TESTER</th>\n",
       "      <th>Tester_1345</th>\n",
       "      <th>Tester_1349</th>\n",
       "      <th>Tester_1397</th>\n",
       "      <th>Tester_2636</th>\n",
       "      <th>Tester_2652</th>\n",
       "      <th>Tester_2683</th>\n",
       "      <th>Tester_2689</th>\n",
       "      <th>Tester_2690</th>\n",
       "      <th>Tester_2721</th>\n",
       "      <th>Tester_2724</th>\n",
       "      <th>...</th>\n",
       "      <th>Tester_821</th>\n",
       "      <th>Tester_8218</th>\n",
       "      <th>Tester_8246</th>\n",
       "      <th>Tester_8248</th>\n",
       "      <th>Tester_8249</th>\n",
       "      <th>Tester_8250</th>\n",
       "      <th>Tester_8253</th>\n",
       "      <th>Tester_8254</th>\n",
       "      <th>Tester_828</th>\n",
       "      <th>Tester_829</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INBRED</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Inbred_1071</th>\n",
       "      <td>0.969057</td>\n",
       "      <td>1.055028</td>\n",
       "      <td>0.887558</td>\n",
       "      <td>0.964557</td>\n",
       "      <td>0.984964</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>0.927634</td>\n",
       "      <td>1.001486</td>\n",
       "      <td>0.795414</td>\n",
       "      <td>0.928092</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052383</td>\n",
       "      <td>1.099251</td>\n",
       "      <td>0.905158</td>\n",
       "      <td>1.030662</td>\n",
       "      <td>1.100013</td>\n",
       "      <td>1.232359</td>\n",
       "      <td>0.986168</td>\n",
       "      <td>0.882199</td>\n",
       "      <td>1.015173</td>\n",
       "      <td>1.030522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inbred_122</th>\n",
       "      <td>0.992539</td>\n",
       "      <td>1.211582</td>\n",
       "      <td>0.975549</td>\n",
       "      <td>1.131133</td>\n",
       "      <td>1.112436</td>\n",
       "      <td>1.009887</td>\n",
       "      <td>0.891741</td>\n",
       "      <td>0.956553</td>\n",
       "      <td>1.153938</td>\n",
       "      <td>0.628051</td>\n",
       "      <td>...</td>\n",
       "      <td>1.137648</td>\n",
       "      <td>1.058705</td>\n",
       "      <td>0.898117</td>\n",
       "      <td>1.139900</td>\n",
       "      <td>0.914537</td>\n",
       "      <td>1.192899</td>\n",
       "      <td>1.137947</td>\n",
       "      <td>0.671808</td>\n",
       "      <td>1.070798</td>\n",
       "      <td>0.974690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inbred_1337</th>\n",
       "      <td>1.088146</td>\n",
       "      <td>1.057429</td>\n",
       "      <td>1.053145</td>\n",
       "      <td>0.859304</td>\n",
       "      <td>1.150580</td>\n",
       "      <td>0.618195</td>\n",
       "      <td>0.988879</td>\n",
       "      <td>1.124274</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>1.114465</td>\n",
       "      <td>...</td>\n",
       "      <td>1.099850</td>\n",
       "      <td>0.818615</td>\n",
       "      <td>0.872485</td>\n",
       "      <td>0.972389</td>\n",
       "      <td>1.101683</td>\n",
       "      <td>1.209382</td>\n",
       "      <td>0.864690</td>\n",
       "      <td>1.087930</td>\n",
       "      <td>0.949592</td>\n",
       "      <td>0.830219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inbred_1339</th>\n",
       "      <td>0.998598</td>\n",
       "      <td>1.063302</td>\n",
       "      <td>1.044683</td>\n",
       "      <td>0.838954</td>\n",
       "      <td>1.182137</td>\n",
       "      <td>0.396613</td>\n",
       "      <td>0.819615</td>\n",
       "      <td>0.966646</td>\n",
       "      <td>0.873175</td>\n",
       "      <td>0.719803</td>\n",
       "      <td>...</td>\n",
       "      <td>1.048709</td>\n",
       "      <td>0.529103</td>\n",
       "      <td>0.700722</td>\n",
       "      <td>0.909809</td>\n",
       "      <td>0.760702</td>\n",
       "      <td>1.008042</td>\n",
       "      <td>0.823863</td>\n",
       "      <td>0.790659</td>\n",
       "      <td>0.830212</td>\n",
       "      <td>0.552364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inbred_1340</th>\n",
       "      <td>0.995254</td>\n",
       "      <td>1.025777</td>\n",
       "      <td>0.752717</td>\n",
       "      <td>1.059824</td>\n",
       "      <td>0.788568</td>\n",
       "      <td>1.553692</td>\n",
       "      <td>1.121638</td>\n",
       "      <td>1.129466</td>\n",
       "      <td>0.582996</td>\n",
       "      <td>1.370789</td>\n",
       "      <td>...</td>\n",
       "      <td>1.075545</td>\n",
       "      <td>1.745535</td>\n",
       "      <td>1.176461</td>\n",
       "      <td>1.154114</td>\n",
       "      <td>1.604635</td>\n",
       "      <td>1.541554</td>\n",
       "      <td>1.125608</td>\n",
       "      <td>1.160014</td>\n",
       "      <td>1.231674</td>\n",
       "      <td>1.596053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  496 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "TESTER       Tester_1345  Tester_1349  Tester_1397  Tester_2636  Tester_2652  \\\n",
       "INBRED                                                                         \n",
       "Inbred_1071     0.969057     1.055028     0.887558     0.964557     0.984964   \n",
       "Inbred_122      0.992539     1.211582     0.975549     1.131133     1.112436   \n",
       "Inbred_1337     1.088146     1.057429     1.053145     0.859304     1.150580   \n",
       "Inbred_1339     0.998598     1.063302     1.044683     0.838954     1.182137   \n",
       "Inbred_1340     0.995254     1.025777     0.752717     1.059824     0.788568   \n",
       "\n",
       "TESTER       Tester_2683  Tester_2689  Tester_2690  Tester_2721  Tester_2724  \\\n",
       "INBRED                                                                         \n",
       "Inbred_1071     0.962251     0.927634     1.001486     0.795414     0.928092   \n",
       "Inbred_122      1.009887     0.891741     0.956553     1.153938     0.628051   \n",
       "Inbred_1337     0.618195     0.988879     1.124274     0.696774     1.114465   \n",
       "Inbred_1339     0.396613     0.819615     0.966646     0.873175     0.719803   \n",
       "Inbred_1340     1.553692     1.121638     1.129466     0.582996     1.370789   \n",
       "\n",
       "TESTER          ...      Tester_821  Tester_8218  Tester_8246  Tester_8248  \\\n",
       "INBRED          ...                                                          \n",
       "Inbred_1071     ...        1.052383     1.099251     0.905158     1.030662   \n",
       "Inbred_122      ...        1.137648     1.058705     0.898117     1.139900   \n",
       "Inbred_1337     ...        1.099850     0.818615     0.872485     0.972389   \n",
       "Inbred_1339     ...        1.048709     0.529103     0.700722     0.909809   \n",
       "Inbred_1340     ...        1.075545     1.745535     1.176461     1.154114   \n",
       "\n",
       "TESTER       Tester_8249  Tester_8250  Tester_8253  Tester_8254  Tester_828  \\\n",
       "INBRED                                                                        \n",
       "Inbred_1071     1.100013     1.232359     0.986168     0.882199    1.015173   \n",
       "Inbred_122      0.914537     1.192899     1.137947     0.671808    1.070798   \n",
       "Inbred_1337     1.101683     1.209382     0.864690     1.087930    0.949592   \n",
       "Inbred_1339     0.760702     1.008042     0.823863     0.790659    0.830212   \n",
       "Inbred_1340     1.604635     1.541554     1.125608     1.160014    1.231674   \n",
       "\n",
       "TESTER       Tester_829  \n",
       "INBRED                   \n",
       "Inbred_1071    1.030522  \n",
       "Inbred_122     0.974690  \n",
       "Inbred_1337    0.830219  \n",
       "Inbred_1339    0.552364  \n",
       "Inbred_1340    1.596053  \n",
       "\n",
       "[5 rows x 496 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>TESTER</th>\n",
       "      <th>Tester_1345</th>\n",
       "      <th>Tester_1349</th>\n",
       "      <th>Tester_1397</th>\n",
       "      <th>Tester_2636</th>\n",
       "      <th>Tester_2652</th>\n",
       "      <th>Tester_2683</th>\n",
       "      <th>Tester_2689</th>\n",
       "      <th>Tester_2690</th>\n",
       "      <th>Tester_2721</th>\n",
       "      <th>Tester_2724</th>\n",
       "      <th>...</th>\n",
       "      <th>Tester_821</th>\n",
       "      <th>Tester_8218</th>\n",
       "      <th>Tester_8246</th>\n",
       "      <th>Tester_8248</th>\n",
       "      <th>Tester_8249</th>\n",
       "      <th>Tester_8250</th>\n",
       "      <th>Tester_8253</th>\n",
       "      <th>Tester_8254</th>\n",
       "      <th>Tester_828</th>\n",
       "      <th>Tester_829</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INBRED</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Inbred_1071</th>\n",
       "      <td>0.960248</td>\n",
       "      <td>1.072859</td>\n",
       "      <td>0.853497</td>\n",
       "      <td>0.954354</td>\n",
       "      <td>0.981084</td>\n",
       "      <td>0.951334</td>\n",
       "      <td>0.905989</td>\n",
       "      <td>1.002726</td>\n",
       "      <td>0.732800</td>\n",
       "      <td>0.906590</td>\n",
       "      <td>...</td>\n",
       "      <td>1.069394</td>\n",
       "      <td>1.130785</td>\n",
       "      <td>0.876549</td>\n",
       "      <td>1.040942</td>\n",
       "      <td>1.131783</td>\n",
       "      <td>1.305137</td>\n",
       "      <td>0.982661</td>\n",
       "      <td>0.846477</td>\n",
       "      <td>1.020654</td>\n",
       "      <td>1.040759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inbred_122</th>\n",
       "      <td>0.991007</td>\n",
       "      <td>1.277923</td>\n",
       "      <td>0.968752</td>\n",
       "      <td>1.172546</td>\n",
       "      <td>1.148055</td>\n",
       "      <td>1.013730</td>\n",
       "      <td>0.858975</td>\n",
       "      <td>0.943870</td>\n",
       "      <td>1.202416</td>\n",
       "      <td>0.513578</td>\n",
       "      <td>...</td>\n",
       "      <td>1.181079</td>\n",
       "      <td>1.077675</td>\n",
       "      <td>0.867327</td>\n",
       "      <td>1.184029</td>\n",
       "      <td>0.888835</td>\n",
       "      <td>1.253450</td>\n",
       "      <td>1.181471</td>\n",
       "      <td>0.570893</td>\n",
       "      <td>1.093515</td>\n",
       "      <td>0.967627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inbred_1337</th>\n",
       "      <td>1.116238</td>\n",
       "      <td>1.076004</td>\n",
       "      <td>1.070392</td>\n",
       "      <td>0.816487</td>\n",
       "      <td>1.198018</td>\n",
       "      <td>0.500668</td>\n",
       "      <td>0.986212</td>\n",
       "      <td>1.163561</td>\n",
       "      <td>0.603596</td>\n",
       "      <td>1.150713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.131569</td>\n",
       "      <td>0.763190</td>\n",
       "      <td>0.833753</td>\n",
       "      <td>0.964613</td>\n",
       "      <td>1.133970</td>\n",
       "      <td>1.275041</td>\n",
       "      <td>0.823543</td>\n",
       "      <td>1.115956</td>\n",
       "      <td>0.934752</td>\n",
       "      <td>0.778390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inbred_1339</th>\n",
       "      <td>0.998943</td>\n",
       "      <td>1.083697</td>\n",
       "      <td>1.059308</td>\n",
       "      <td>0.789831</td>\n",
       "      <td>1.239354</td>\n",
       "      <td>0.210427</td>\n",
       "      <td>0.764500</td>\n",
       "      <td>0.957091</td>\n",
       "      <td>0.834656</td>\n",
       "      <td>0.633761</td>\n",
       "      <td>...</td>\n",
       "      <td>1.064582</td>\n",
       "      <td>0.383970</td>\n",
       "      <td>0.608767</td>\n",
       "      <td>0.882642</td>\n",
       "      <td>0.687332</td>\n",
       "      <td>1.011313</td>\n",
       "      <td>0.770064</td>\n",
       "      <td>0.726572</td>\n",
       "      <td>0.778381</td>\n",
       "      <td>0.414438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inbred_1340</th>\n",
       "      <td>0.994563</td>\n",
       "      <td>1.034544</td>\n",
       "      <td>0.676873</td>\n",
       "      <td>1.079141</td>\n",
       "      <td>0.723833</td>\n",
       "      <td>1.726039</td>\n",
       "      <td>1.160108</td>\n",
       "      <td>1.170362</td>\n",
       "      <td>0.454562</td>\n",
       "      <td>1.486461</td>\n",
       "      <td>...</td>\n",
       "      <td>1.099733</td>\n",
       "      <td>1.977327</td>\n",
       "      <td>1.231918</td>\n",
       "      <td>1.202647</td>\n",
       "      <td>1.792767</td>\n",
       "      <td>1.710140</td>\n",
       "      <td>1.165308</td>\n",
       "      <td>1.210375</td>\n",
       "      <td>1.304240</td>\n",
       "      <td>1.781526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  496 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "TESTER       Tester_1345  Tester_1349  Tester_1397  Tester_2636  Tester_2652  \\\n",
       "INBRED                                                                         \n",
       "Inbred_1071     0.960248     1.072859     0.853497     0.954354     0.981084   \n",
       "Inbred_122      0.991007     1.277923     0.968752     1.172546     1.148055   \n",
       "Inbred_1337     1.116238     1.076004     1.070392     0.816487     1.198018   \n",
       "Inbred_1339     0.998943     1.083697     1.059308     0.789831     1.239354   \n",
       "Inbred_1340     0.994563     1.034544     0.676873     1.079141     0.723833   \n",
       "\n",
       "TESTER       Tester_2683  Tester_2689  Tester_2690  Tester_2721  Tester_2724  \\\n",
       "INBRED                                                                         \n",
       "Inbred_1071     0.951334     0.905989     1.002726     0.732800     0.906590   \n",
       "Inbred_122      1.013730     0.858975     0.943870     1.202416     0.513578   \n",
       "Inbred_1337     0.500668     0.986212     1.163561     0.603596     1.150713   \n",
       "Inbred_1339     0.210427     0.764500     0.957091     0.834656     0.633761   \n",
       "Inbred_1340     1.726039     1.160108     1.170362     0.454562     1.486461   \n",
       "\n",
       "TESTER          ...      Tester_821  Tester_8218  Tester_8246  Tester_8248  \\\n",
       "INBRED          ...                                                          \n",
       "Inbred_1071     ...        1.069394     1.130785     0.876549     1.040942   \n",
       "Inbred_122      ...        1.181079     1.077675     0.867327     1.184029   \n",
       "Inbred_1337     ...        1.131569     0.763190     0.833753     0.964613   \n",
       "Inbred_1339     ...        1.064582     0.383970     0.608767     0.882642   \n",
       "Inbred_1340     ...        1.099733     1.977327     1.231918     1.202647   \n",
       "\n",
       "TESTER       Tester_8249  Tester_8250  Tester_8253  Tester_8254  Tester_828  \\\n",
       "INBRED                                                                        \n",
       "Inbred_1071     1.131783     1.305137     0.982661     0.846477    1.020654   \n",
       "Inbred_122      0.888835     1.253450     1.181471     0.570893    1.093515   \n",
       "Inbred_1337     1.133970     1.275041     0.823543     1.115956    0.934752   \n",
       "Inbred_1339     0.687332     1.011313     0.770064     0.726572    0.778381   \n",
       "Inbred_1340     1.792767     1.710140     1.165308     1.210375    1.304240   \n",
       "\n",
       "TESTER       Tester_829  \n",
       "INBRED                   \n",
       "Inbred_1071    1.040759  \n",
       "Inbred_122     0.967627  \n",
       "Inbred_1337    0.778390  \n",
       "Inbred_1339    0.414438  \n",
       "Inbred_1340    1.781526  \n",
       "\n",
       "[5 rows x 496 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.apply(correction).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Inbred_1071', 'Inbred_122', 'Inbred_1337', 'Inbred_1339',\n",
       "       'Inbred_1340', 'Inbred_1341', 'Inbred_1342', 'Inbred_1344',\n",
       "       'Inbred_1345', 'Inbred_1346',\n",
       "       ...\n",
       "       'Inbred_801', 'Inbred_803', 'Inbred_804', 'Inbred_805', 'Inbred_810',\n",
       "       'Inbred_818', 'Inbred_819', 'Inbred_821', 'Inbred_828', 'Inbred_836'],\n",
       "      dtype='object', name='INBRED', length=593)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FwWYwdPjbmKi",
    "outputId": "b95e979a-f0ef-4f36-d863-a49df07b6bb8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmax = 30\n",
    "ks  = range(2, kmax+1, 2)\n",
    "alphas = [10**i for i in range(-5,0)]\n",
    "betas = [10**i for i in range(-5,0)]\n",
    "lambdas = [10**i for i in range(-5,0)]\n",
    "best_test_error = {}\n",
    "for k in ks:\n",
    "    print(f'running k = {k}')\n",
    "    if k > 5:\n",
    "        for a in alphas:\n",
    "            for beta in betas:\n",
    "                for lambda_bias in lambdas:\n",
    "                    \n",
    "                    mf = MF(train_df.values, K=k, alpha=a, beta=beta, iterations=300, lambda_bias=lambda_bias, test=test_df.values)\n",
    "                    training_process, test_process = mf.train()\n",
    "                    best_test_error[(k, a, beta, lambda_bias)] = min(test_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AM0cM0u_bmKu"
   },
   "outputs": [],
   "source": [
    "mf = MF(train_.values, 26, 0.001, 0.001, 150, 1e-05, test=test_.values)\n",
    "training_process, test_process = mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.all((train_df.values * test_df.values) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKrlWcX_bmKy",
    "outputId": "09bcf481-05eb-4830-8a57-a8bb3518927a"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].plot(test_process)\n",
    "axs[0].set_title('Test error')\n",
    "axs[1].plot(list(map(lambda x: x[1], training_process)))\n",
    "axs[1].set_title('Training  error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "818rO1YKbmK1",
    "outputId": "0f8d5fad-5075-46db-bf8d-f499165b40e8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-85dd1d13e4bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mgca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_' is not defined"
     ]
    }
   ],
   "source": [
    "def abline():\n",
    "    gca = plt.gca()\n",
    "    gca.set_autoscale_on(False)\n",
    "    gca.plot(gca.get_xlim(),gca.get_ylim(), 'red')\n",
    "    \n",
    "test = test_.values\n",
    "x = test[test.nonzero()].flatten()\n",
    "y = mf.full_matrix()[test.nonzero()].flatten()\n",
    "plt.scatter(x, y, alpha = 0.5)\n",
    "plt.xlabel(\"actual test\")\n",
    "plt.ylabel(\"predicted test\")\n",
    "abline()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_ddx86ubmK3"
   },
   "outputs": [],
   "source": [
    "to_write = open('split1.txt', 'a')\n",
    "to_write.write(\"a\\\\n\")\n",
    "to_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMfNPCcJbmK4"
   },
   "outputs": [],
   "source": [
    "# mf = MF(train_df.values, K=10, alpha=0.01, beta=0.1, iterations=300, lambda_bias=0.15, test=test_df.values)\n",
    "# training_process, test_process = mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hehFoojxbmK7",
    "outputId": "836ae917-1fba-45de-f93c-c4cd01297b3a"
   },
   "outputs": [],
   "source": [
    "plt.hist(mf.full_matrix().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFs9kj1cbmK8",
    "outputId": "d9866935-94c4-4680-d87b-45da67e7181d"
   },
   "outputs": [],
   "source": [
    "best_test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1ncx3fRbmK-"
   },
   "outputs": [],
   "source": [
    "ordered_results = sorted(best_test_error.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8vMPhd2bmLA",
    "outputId": "0d9234c9-227c-45c1-9ef5-da67259207a2"
   },
   "outputs": [],
   "source": [
    "ordered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqYb3-M6bmLC",
    "outputId": "823baa4d-3d24-4a43-a1ca-d2ac3a868fd0"
   },
   "outputs": [],
   "source": [
    "best_test_error.itertuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MphTv4w6bmLH",
    "outputId": "bb28465e-66d8-4b62-a356-7ae4bc796b6f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max(best_test_error.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmJcB6JXbmLI"
   },
   "outputs": [],
   "source": [
    "# elements = [val for i, val in enumerate(ordered_results) if i < 20]\n",
    "count = 0\n",
    "with open('results.txt', 'w') as f:\n",
    "    while count < 20:\n",
    "        val = ordered_results[count]\n",
    "        f.write(str(val)[1:-1] + '\\n')\n",
    "        count +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsrdF0ExcXbU"
   },
   "outputs": [],
   "source": [
    "k, a, beta, lambda_bias = 26, 0.001, 0.001, 1e-05\n",
    "mf = MF(train_df.values, K=k, alpha=a, beta=beta, iterations=300, lambda_bias=lambda_bias, test=test_df.values)\n",
    "training_process, test_process = mf.train()\n",
    "plt.plot(test_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "4Mi2cGmId1Qt",
    "outputId": "7b006eb6-5262-4b27-d953-b6fec1feca03"
   },
   "outputs": [],
   "source": [
    "plt.plot(test_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0pFoobYPd5os",
    "outputId": "bfec9eed-e398-46d0-9f18-73f6258178bb"
   },
   "outputs": [],
   "source": [
    "print(min(test_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2XRR06LbmLL"
   },
   "outputs": [],
   "source": [
    "# another MF method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QR_5FK70dP6Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFtQ1x6O2Gf7"
   },
   "outputs": [],
   "source": [
    "class ExplicitMF():\n",
    "    def __init__(self, \n",
    "                 ratings,\n",
    "                 n_factors=40,\n",
    "                 learning='sgd',\n",
    "                 item_fact_reg=0.1, \n",
    "                 user_fact_reg=0.1,\n",
    "                 item_bias_reg=0.1,\n",
    "                 user_bias_reg=0.1,\n",
    "                 verbose=False):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict empty \n",
    "        entries in a matrix. The terminology assumes a \n",
    "        ratings matrix which is ~ user x item\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors to use in matrix \n",
    "            factorization model\n",
    "        learning : (str)\n",
    "            Method of optimization. Options include \n",
    "            'sgd' or 'als'.\n",
    "        \n",
    "        item_fact_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_fact_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "            \n",
    "        item_bias_reg : (float)\n",
    "            Regularization term for item biases\n",
    "        \n",
    "        user_bias_reg : (float)\n",
    "            Regularization term for user biases\n",
    "        \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_fact_reg = item_fact_reg\n",
    "        self.user_fact_reg = user_fact_reg\n",
    "        self.item_bias_reg = item_bias_reg\n",
    "        self.user_bias_reg = user_bias_reg\n",
    "        self.learning = learning\n",
    "        if self.learning == 'sgd':\n",
    "            self.sample_row, self.sample_col = self.ratings.nonzero()\n",
    "            self.n_samples = len(self.sample_row)\n",
    "        self._v = verbose\n",
    "\n",
    "    def als_step(self,\n",
    "                 latent_vectors,\n",
    "                 fixed_vecs,\n",
    "                 ratings,\n",
    "                 _lambda,\n",
    "                 type='user'):\n",
    "        \"\"\"\n",
    "        One of the two ALS steps. Solve for the latent vectors\n",
    "        specified by type.\n",
    "        \"\"\"\n",
    "        if type == 'user':\n",
    "            # Precompute\n",
    "            YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(YTY.shape[0]) * _lambda\n",
    "\n",
    "            for u in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[u, :] = solve((YTY + lambdaI), \n",
    "                                             ratings[u, :].dot(fixed_vecs))\n",
    "        elif type == 'item':\n",
    "            # Precompute\n",
    "            XTX = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(XTX.shape[0]) * _lambda\n",
    "            \n",
    "            for i in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[i, :] = solve((XTX + lambdaI), \n",
    "                                             ratings[:, i].T.dot(fixed_vecs))\n",
    "        return latent_vectors\n",
    "\n",
    "    def train(self, n_iter=10, learning_rate=0.01):\n",
    "        \"\"\" Train model for n_iter iterations from scratch.\"\"\"\n",
    "        # initialize latent vectors        \n",
    "        self.user_vecs = np.random.normal(scale=1./self.n_factors,\\\n",
    "                                          size=(self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.normal(scale=1./self.n_factors,\n",
    "                                          size=(self.n_items, self.n_factors))\n",
    "        self.user_vecs_velocity = np.zeros((self.n_users, self.n_factors))\n",
    "        self.item_vecs_velocity = np.zeros((self.n_items, self.n_factors))\n",
    "\n",
    "        if self.learning == 'als':\n",
    "            self.partial_train(n_iter)\n",
    "        elif self.learning == 'sgd':\n",
    "            self.learning_rate = learning_rate\n",
    "            self.momentum = 0.9\n",
    "            self.user_bias = np.zeros(self.n_users)\n",
    "            self.item_bias = np.zeros(self.n_items)\n",
    "            self.user_bias_velocity = np.zeros(self.n_users)\n",
    "            self.item_bias_velocity = np.zeros(self.n_items)\n",
    "            self.global_bias = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "            self.partial_train(n_iter)\n",
    "    \n",
    "    \n",
    "    def partial_train(self, n_iter):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations. Can be \n",
    "        called multiple times for further training.\n",
    "        \"\"\"\n",
    "        ctr = 1\n",
    "        while ctr <= n_iter:\n",
    "            if ctr % 10 == 0 and self._v:\n",
    "                print ('\\tcurrent iteration: {}'.format(ctr))\n",
    "            if self.learning == 'als':\n",
    "                self.user_vecs = self.als_step(self.user_vecs, \n",
    "                                               self.item_vecs, \n",
    "                                               self.ratings, \n",
    "                                               self.user_fact_reg, \n",
    "                                               type='user')\n",
    "                self.item_vecs = self.als_step(self.item_vecs, \n",
    "                                               self.user_vecs, \n",
    "                                               self.ratings, \n",
    "                                               self.item_fact_reg, \n",
    "                                               type='item')\n",
    "            elif self.learning == 'sgd':\n",
    "                self.training_indices = np.arange(self.n_samples)\n",
    "                np.random.shuffle(self.training_indices)\n",
    "                self.sgd()\n",
    "            ctr += 1\n",
    "\n",
    "    def sgd(self):\n",
    "        for idx in self.training_indices:\n",
    "            u = self.sample_row[idx]\n",
    "            i = self.sample_col[idx]\n",
    "            prediction = self.predict(u, i)\n",
    "            e = (self.ratings[u,i] - prediction) # error\n",
    "            \n",
    "            # Update biases\n",
    "            self.user_bias_velocity[u] = self.momentum * self.user_bias_velocity[u] + \\\n",
    "                                        self.learning_rate * (e - self.user_bias_reg * self.user_bias[u])\n",
    "            self.user_bias[u] += self.user_bias_velocity[u]\n",
    "\n",
    "            self.item_bias_velocity[i] = self.momentum * self.item_bias_velocity[i] + \\\n",
    "                                        self.learning_rate * (e - self.item_bias_reg * self.item_bias[i])\n",
    "            self.item_bias[i] += self.item_bias_velocity[i]\n",
    "\n",
    "            # self.user_bias[u] += self.learning_rate * \\\n",
    "            #                     (e - self.user_bias_reg * self.user_bias[u])\n",
    "            # self.item_bias[i] += self.learning_rate * \\\n",
    "            #                     (e - self.item_bias_reg * self.item_bias[i])\n",
    "            \n",
    "            #Update latent factors\n",
    "            self.user_vecs_velocity[u, :] = self.momentum * self.user_vecs_velocity[u, :] + \\\n",
    "                                        self.learning_rate * \\\n",
    "                                        (e * self.item_vecs[i, :] - \\\n",
    "                                        self.user_fact_reg * self.user_vecs[u,:])\n",
    "            self.user_vecs[u, :] += self.user_vecs_velocity[u, :]\n",
    "\n",
    "            self.item_vecs_velocity[i, :] = self.momentum * self.item_vecs_velocity[i, :] + \\\n",
    "                                        self.learning_rate * \\\n",
    "                                        (e * self.user_vecs[u, :] - \\\n",
    "                                        self.item_fact_reg * self.item_vecs[i,:])\n",
    "            self.item_vecs[i :] += self.item_vecs_velocity[i, :]\n",
    "\n",
    "            # self.user_vecs[u, :] += self.learning_rate * \\\n",
    "            #                         (e * self.item_vecs[i, :] - \\\n",
    "            #                          self.user_fact_reg * self.user_vecs[u,:])\n",
    "            # self.item_vecs[i, :] += self.learning_rate * \\\n",
    "            #                         (e * self.user_vecs[u, :] - \\\n",
    "            #                          self.item_fact_reg * self.item_vecs[i,:])\n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction.\"\"\"\n",
    "        if self.learning == 'als':\n",
    "            return self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "        elif self.learning == 'sgd':\n",
    "            prediction = self.global_bias + self.user_bias[u] + self.item_bias[i]\n",
    "            prediction += self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "            return prediction\n",
    "    \n",
    "    def predict_all(self):\n",
    "        \"\"\" Predict ratings for every user and item.\"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0], \n",
    "                                self.item_vecs.shape[0]))\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            for i in range(self.item_vecs.shape[0]):\n",
    "                predictions[u, i] = self.predict(u, i)\n",
    "                \n",
    "        return predictions\n",
    "    \n",
    "    def calculate_learning_curve(self, iter_array, test, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Keep track of MSE as a function of training iterations.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        iter_array : (list)\n",
    "            List of numbers of iterations to train for each step of \n",
    "            the learning curve. e.g. [1, 5, 10, 20]\n",
    "        test : (2D ndarray)\n",
    "            Testing dataset (assumed to be user x item).\n",
    "        \n",
    "        The function creates two new class attributes:\n",
    "        \n",
    "        train_mse : (list)\n",
    "            Training data MSE values for each value of iter_array\n",
    "        test_mse : (list)\n",
    "            Test data MSE values for each value of iter_array\n",
    "        \"\"\"\n",
    "        iter_array.sort()\n",
    "        self.train_mse =[]\n",
    "        self.test_mse = []\n",
    "        iter_diff = 0\n",
    "        for (i, n_iter) in enumerate(iter_array):\n",
    "            if self._v:\n",
    "                print ('Iteration: {}'.format(n_iter))\n",
    "            if i == 0:\n",
    "                self.train(n_iter - iter_diff, learning_rate)\n",
    "            else:\n",
    "                self.partial_train(n_iter - iter_diff)\n",
    "\n",
    "            predictions = self.predict_all()\n",
    "\n",
    "            self.train_mse += [get_mse(predictions, self.ratings)]\n",
    "            self.test_mse += [get_mse(predictions, test)]\n",
    "            if self._v:\n",
    "                print ('Train mse: ' + str(self.train_mse[-1]))\n",
    "                print ('Test mse: ' + str(self.test_mse[-1]))\n",
    "            iter_diff = n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5ua3Jkaehe1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "def plot_learning_curve(iter_array, model):\n",
    "    plt.plot(iter_array, model.train_mse, \\\n",
    "             label='Training', linewidth=5)\n",
    "    plt.plot(iter_array, model.test_mse, \\\n",
    "             label='Test', linewidth=5)\n",
    "\n",
    "\n",
    "    plt.xticks(fontsize=16);\n",
    "    plt.yticks(fontsize=16);\n",
    "    plt.xlabel('iterations', fontsize=30);\n",
    "    plt.ylabel('MSE', fontsize=30);\n",
    "    plt.legend(loc='best', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DFzGgi4dGcz"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc6kIHKtdJJm"
   },
   "outputs": [],
   "source": [
    "#MF_SGD = ExplicitMF(train, 40, learning='sgd', verbose=True)\n",
    "MF_SGD = ExplicitMF(train_df.values,\n",
    "                    n_factors=40,\n",
    "                    learning='sgd',\n",
    "                    \n",
    "                    item_fact_reg=0.1, \n",
    "                    user_fact_reg=0.1,\n",
    "                    item_bias_reg=0.1,\n",
    "                    user_bias_reg=0.1,\n",
    "                    verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 100, 200,300]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test_df.values, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "LYDIYcRDdy3p",
    "outputId": "7102f6ae-d42a-4486-e904-81c80c24219e"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(iter_array, MF_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oXOSQ1PSeIJK",
    "outputId": "5d8cfcbc-8290-4d0d-9f55-7f902755187a"
   },
   "outputs": [],
   "source": [
    "iter_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E719bdBmeuFQ",
    "outputId": "3f7a08b4-a27c-42a6-bacd-fcd687cfa468"
   },
   "outputs": [],
   "source": [
    "get_mse(MF_SGD.predict_all(),test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YJlOKVqXe6GX",
    "outputId": "8950986e-170c-4961-e603-9a581108defa"
   },
   "outputs": [],
   "source": [
    "get_mse(mf.full_matrix(),test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSLwTla4fDeN"
   },
   "outputs": [],
   "source": [
    "# try to take log, train, then exponentiate back\n",
    "train_df_log = np.ma.log(train_df.values)\n",
    "train_df_log = train_df_log.filled(0)\n",
    "test_df_log = np.ma.log(test_df.values)\n",
    "test_df_log = test_df_log.filled(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "8G_cVAVeh9Qv",
    "outputId": "19fbe1de-e85c-4ad8-c0bf-11ff4aa0157a"
   },
   "outputs": [],
   "source": [
    "k, a, beta, lambda_bias = 26, 0.001, 0.001, 1e-05\n",
    "mf = MF(train_df_log, K=k, alpha=a, beta=beta, iterations=300, lambda_bias=lambda_bias, test=test_df_log)\n",
    "training_process, test_process = mf.train()\n",
    "plt.plot(test_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_yCf-izqh9E0",
    "outputId": "455735f2-5b55-4e0a-9e2b-0f93c8e99d65"
   },
   "outputs": [],
   "source": [
    "get_mse(np.exp(mf.full_matrix()),test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "oH6dSMUVgbow",
    "outputId": "d5016d1b-63cf-4582-f87a-d90d18a3ed91"
   },
   "outputs": [],
   "source": [
    "MF_SGD = ExplicitMF(train_df.values,\n",
    "                    n_factors=40,\n",
    "                    learning='sgd',\n",
    "                    item_fact_reg=0.1, \n",
    "                    user_fact_reg=0.1,\n",
    "                    item_bias_reg=0.1,\n",
    "                    user_bias_reg=0.1,\n",
    "                    verbose=False)\n",
    "iter_array = [1, 2, 5, 10, 25, 50]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test_df.values, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "zMLXDeOvV_e-",
    "outputId": "ca1dde91-c814-4a8d-f2eb-72d7890943f2"
   },
   "outputs": [],
   "source": [
    "MF_SGD = ExplicitMF(train,\n",
    "                    n_factors=40,\n",
    "                    learning='sgd',\n",
    "                    item_fact_reg=0.1, \n",
    "                    user_fact_reg=0.1,\n",
    "                    item_bias_reg=0.1,\n",
    "                    user_bias_reg=0.1,\n",
    "                    verbose=True)\n",
    "iter_array = [1, 2, 5, 10, 25, 50]\n",
    "MF_SGD.calculate_learning_curve(iter_array, test, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ohNJaeuAWMrZ",
    "outputId": "b0247317-3e6b-4e5f-c25e-1f92620f8f39"
   },
   "outputs": [],
   "source": [
    "get_mse(np.exp(MF_SGD.predict_all()),np.exp(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "tM4-qwKdhgWC",
    "outputId": "dfdcdba6-d447-415b-9787-b45a0da8de3f"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(iter_array, MF_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "BEokm4zw7taf",
    "outputId": "d45fe805-c359-4729-d524-43c330d42183"
   },
   "outputs": [],
   "source": [
    "from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cm_da4hY8Bcd"
   },
   "outputs": [],
   "source": [
    "X_incomplete = train_df.replace(0,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdUHcuTT-Znl"
   },
   "outputs": [],
   "source": [
    "X_incomplete_log = np.log(X_incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "colab_type": "code",
    "id": "kN5FX2Ib8YVd",
    "outputId": "8c4dedde-5a1d-4eb9-81a6-7993c9b414ae"
   },
   "outputs": [],
   "source": [
    "X_filled_nnm = NuclearNormMinimization().fit_transform(X_incomplete.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5AGclE_BNzj"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_incomplete_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-139e4b5ac700>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnull_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_incomplete_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_incomplete_log' is not defined"
     ]
    }
   ],
   "source": [
    "null_mat = X_incomplete_log.isnull().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BrOwsBfNCgXi",
    "outputId": "078cd9a2-4f7e-4645-e49a-6fc941b4cd1b"
   },
   "outputs": [],
   "source": [
    "null_mat[0,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z6tAQ-AQClOG",
    "outputId": "a007d505-515d-4b21-ff8e-81a88e79a033"
   },
   "outputs": [],
   "source": [
    "null_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhMB0R7dC19J"
   },
   "outputs": [],
   "source": [
    "X_incomplete = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "t0iddVhx_KnJ",
    "outputId": "878a47d6-1826-4902-fb46-214a05ed5f44"
   },
   "outputs": [],
   "source": [
    "for i in range(len(null_mat)):\n",
    "    #print(train_df_log[i,0])\n",
    "    if null_mat[i,:].sum() == 496:\n",
    "        print(\"zero row\")\n",
    "        idx = np.random.choice(495)\n",
    "        X_incomplete.iloc[i,idx] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnYT0epoAU7d"
   },
   "outputs": [],
   "source": [
    "X_incomplete.replace(0, np.nan, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "vyj2oWg3Dof_",
    "outputId": "19cf4c30-7f09-4d73-aa36-5d81db3da498"
   },
   "outputs": [],
   "source": [
    "X_incomplete_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukyZ6bZV-uVF"
   },
   "outputs": [],
   "source": [
    "si = SoftImpute(max_iters = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBNvkREi8ynp"
   },
   "outputs": [],
   "source": [
    "# X_incomplete_normalized = BiScaler().fit_transform(train_na)\n",
    "X_filled_softimpute = si.fit_transform(train_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2vl0iQWT9hN9",
    "outputId": "dc13f44b-e4e8-4452-9023-1ac08d887467"
   },
   "outputs": [],
   "source": [
    "get_mse(np.exp(X_filled_softimpute), np.exp(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "SB-xMg7vaYkX",
    "outputId": "5f3ed116-1bc6-409c-ed3c-82e052000e69"
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.exp(test[test.nonzero()]).flatten(), np.exp(X_filled_softimpute[test.nonzero()].flatten()), alpha = 0.5)\n",
    "#plt.plot(np.exp(test[test.nonzero()]).flatten(), alpha = 0.5)\n",
    "plt.xlabel(\"test\")\n",
    "plt.ylabel(\"pred test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iU82IrHVaGCc",
    "outputId": "f0ea9603-9dd8-4342-de07-88a16475cd4f"
   },
   "outputs": [],
   "source": [
    "np.sqrt(0.00017838840904557725)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_1xVgy0XJvP2",
    "outputId": "de96d182-3094-4661-b0d5-fc9a9463149a"
   },
   "outputs": [],
   "source": [
    "np.exp(train).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UttwhX-9FrD9",
    "outputId": "df393c27-4112-4ad7-903e-fbabce21668f"
   },
   "outputs": [],
   "source": [
    "np.exp(X_filled_softimpute).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "32DSrBid-Owg",
    "outputId": "f8a9c134-c70a-4853-cde6-369c38a6c8d2"
   },
   "outputs": [],
   "source": [
    "np.exp(X_filled_softimpute).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcdFmdKoGlgz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aVxSKP3B6W61",
    "outputId": "d5340421-021a-408b-b2f8-b70c859331d9"
   },
   "outputs": [],
   "source": [
    "get_mse(MF_SGD.predict_all(),test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QQ3SqmcWh3tA",
    "outputId": "57c756bd-193f-4fee-957f-8586d33b0ec2"
   },
   "outputs": [],
   "source": [
    "get_mse(np.exp(MF_SGD.predict_all()),test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyFJtiTNiNhl"
   },
   "outputs": [],
   "source": [
    "res = np.exp(MF_SGD.predict_all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AbswyQGhiZo-",
    "outputId": "fade015e-7ca6-467d-a202-67a17de1e571"
   },
   "outputs": [],
   "source": [
    "res.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wKsYKgBvivEV",
    "outputId": "5f249f6c-79aa-4777-b4c4-dbbd8d9c6e83"
   },
   "outputs": [],
   "source": [
    "res.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GKzuq53Diwyq",
    "outputId": "88691997-1a54-437c-f083-c55d7bd6e8cc"
   },
   "outputs": [],
   "source": [
    "train_df.values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9eoGo4e8i0K5",
    "outputId": "e4e6384e-593f-4f78-fb57-2ee9fd75beb7"
   },
   "outputs": [],
   "source": [
    "res.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "E2t7XYqInpNS",
    "outputId": "5e5b4790-acd9-4791-9c08-2c2088a02268"
   },
   "outputs": [],
   "source": [
    "np.exp(MF_SGD.predict_all())\n",
    "plt.hist(np.exp(MF_SGD.predict_all())[test.nonzero()].flatten(), alpha = 0.5, label = \"test prediction\",bins = 20)\n",
    "plt.title(\"Histogram of Test Prediction vs Test Data\")\n",
    "plt.hist(np.exp(test)[test.nonzero()].flatten(), alpha = 0.5, label = \"test data\",bins = 20)\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "m3nGrW7Vn50m",
    "outputId": "e98fb5ef-33d0-4e28-b256-a64837b640c8"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.exp(MF_SGD.predict_all())[train.nonzero()].flatten(), alpha = 0.5, label = \"train prediction\")\n",
    "plt.title(\"Histogram of Train Prediction vs Train Data\")\n",
    "plt.hist(np.exp(train)[train.nonzero()].flatten(), alpha = 0.5, label = \"train data\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "pZN-6Uh2Gnwj",
    "outputId": "f3f73dfa-7171-4066-bdec-968e3b67ff1a"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.exp(X_filled_softimpute)[test.nonzero()].flatten(), alpha = 0.5, label = \"test prediction\")\n",
    "plt.title(\"Histogram of Test Prediction vs Test Data\")\n",
    "plt.hist(np.exp(test)[test.nonzero()].flatten(), alpha = 0.5, label = \"test data\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "6WlxfeItZbZI",
    "outputId": "59bbfad0-715d-4db1-d618-04c92322b796"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.exp(X_filled_softimpute)[train.nonzero()].flatten(), alpha = 0.5, label = \"train prediction\")\n",
    "plt.title(\"Histogram of Train Prediction vs Train Data\")\n",
    "plt.hist(np.exp(train)[train.nonzero()].flatten(), alpha = 0.5, label = \"train data\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZvF4jHweY-ab",
    "outputId": "0f3176fd-9b88-4044-9a11-17e8f27c6228"
   },
   "outputs": [],
   "source": [
    "np.exp(X_filled_softimpute)[test.nonzero()].flatten().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hvH4hi-nZBEd",
    "outputId": "2c179ada-abc9-4228-e03b-c073c4339c8e"
   },
   "outputs": [],
   "source": [
    "np.exp(test)[test.nonzero()].flatten().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "lV1ce0DFYKnr",
    "outputId": "6fae3fda-8d3b-404d-a730-2d8f8f594017"
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qd6PfA0POiHr",
    "outputId": "449c76f9-08f0-4da3-9107-6133262e477f"
   },
   "outputs": [],
   "source": [
    "np.all(train*test) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "HxOit7lpGwaH",
    "outputId": "d9623e17-0b4c-4f8e-adaa-487e9adc8b99"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.exp(X_filled_softimpute)[test.nonzero()].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "A08n0V8aG1WF",
    "outputId": "321be8d7-ae81-4ccf-b3f0-8e542237cb13"
   },
   "outputs": [],
   "source": [
    "plt.hist(test_df.values[test_df.values.nonzero()].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "TeOj1S3Fi7WX",
    "outputId": "df7c31d4-f0ad-4f55-e825-8991511d9965"
   },
   "outputs": [],
   "source": [
    "plt.hist(res[train_df.values.nonzero()].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "4QXcboBIi9w5",
    "outputId": "3936dd19-7abe-443e-f1ac-35aaab4fa601"
   },
   "outputs": [],
   "source": [
    "plt.hist(train_df.values[train_df.values.nonzero()].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RqfFkQ-gjIl4",
    "outputId": "c1824de3-ec0e-48dc-c136-fbc1b99bac9c"
   },
   "outputs": [],
   "source": [
    "train_df.values.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "gIeZ0UaCjUZQ",
    "outputId": "30df9729-18d9-4419-b76a-280571eb6987"
   },
   "outputs": [],
   "source": [
    "iter_array = [1, 2, 5, 10, 25, 50, 100, 200,250]\n",
    "learning_rates = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "\n",
    "best_params = {}\n",
    "best_params['learning_rate'] = None\n",
    "best_params['n_iter'] = 0\n",
    "best_params['train_mse'] = np.inf\n",
    "best_params['test_mse'] = np.inf\n",
    "best_params['model'] = None\n",
    "\n",
    "\n",
    "for rate in learning_rates:\n",
    "    print ('Rate: {}'.format(rate))\n",
    "    MF_SGD = ExplicitMF(train_df_log, n_factors=35, learning='sgd')\n",
    "    MF_SGD.calculate_learning_curve(iter_array, test_df_log, learning_rate=rate)\n",
    "    min_idx = np.argmin(MF_SGD.test_mse)\n",
    "    if MF_SGD.test_mse[min_idx] < best_params['test_mse']:\n",
    "        best_params['n_iter'] = iter_array[min_idx]\n",
    "        best_params['learning_rate'] = rate\n",
    "        best_params['train_mse'] = MF_SGD.train_mse[min_idx]\n",
    "        best_params['test_mse'] = MF_SGD.test_mse[min_idx]\n",
    "        best_params['model'] = MF_SGD\n",
    "        print ('New optimal hyperparameters')\n",
    "        print (pd.Series(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "myenpXyYkM61",
    "outputId": "87253f7e-3f63-44e8-8310-3fb9475bb84f"
   },
   "outputs": [],
   "source": [
    "best_params #for learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zPioO-5mmdpO",
    "outputId": "26982db2-c8d2-4c5f-dfc1-79cd85bf4dc1"
   },
   "outputs": [],
   "source": [
    "iter_array = [1, 2, 5, 10, 25, 50, 100, 200, 250]\n",
    "latent_factors = [ 5, 10, 20, 25, 30, 35, 40]\n",
    "regularizations = [0.001, 0.01, 0.1, 1.]\n",
    "regularizations.sort()\n",
    "\n",
    "best_params = {}\n",
    "best_params['n_factors'] = latent_factors[0]\n",
    "best_params['reg'] = regularizations[0]\n",
    "best_params['n_iter'] = 0\n",
    "best_params['train_mse'] = np.inf\n",
    "best_params['test_mse'] = np.inf\n",
    "best_params['model'] = None\n",
    "\n",
    "for fact in latent_factors:\n",
    "    print ('Factors: {}'.format(fact))\n",
    "    for reg in regularizations:\n",
    "        print ('Regularization: {}'.format(reg))\n",
    "        MF_SGD = ExplicitMF(train_df_log, n_factors=fact, learning='sgd',\\\n",
    "                            user_fact_reg=reg, item_fact_reg=reg, \\\n",
    "                            user_bias_reg=reg, item_bias_reg=reg)\n",
    "        MF_SGD.calculate_learning_curve(iter_array, test_df_log, learning_rate=0.001)\n",
    "        min_idx = np.argmin(MF_SGD.test_mse)\n",
    "        if MF_SGD.test_mse[min_idx] < best_params['test_mse']:\n",
    "            best_params['n_factors'] = fact\n",
    "            best_params['reg'] = reg\n",
    "            best_params['n_iter'] = iter_array[min_idx]\n",
    "            best_params['train_mse'] = MF_SGD.train_mse[min_idx]\n",
    "            best_params['test_mse'] = MF_SGD.test_mse[min_idx]\n",
    "            best_params['model'] = MF_SGD\n",
    "            print ('New optimal hyperparameters')\n",
    "            print (pd.Series(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "rk1uAd6GyJmd",
    "outputId": "9ca10b38-3638-4f26-e2bb-b67a426109e5"
   },
   "outputs": [],
   "source": [
    "best_params #for factors and reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvBNz4wIMJET"
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import solve\n",
    "\n",
    "class ExplicitMF():\n",
    "    def __init__(self, \n",
    "                 ratings, \n",
    "                 n_factors=40, \n",
    "                 item_reg=0.0, \n",
    "                 user_reg=0.0,\n",
    "                 verbose=False):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict empty \n",
    "        entries in a matrix. The terminology assumes a \n",
    "        ratings matrix which is ~ user x item\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors to use in matrix \n",
    "            factorization model\n",
    "        \n",
    "        item_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "        \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_reg = item_reg\n",
    "        self.user_reg = user_reg\n",
    "        self._v = verbose\n",
    "\n",
    "    def als_step(self,\n",
    "                 latent_vectors,\n",
    "                 fixed_vecs,\n",
    "                 ratings,\n",
    "                 _lambda,\n",
    "                 type='user'):\n",
    "        \"\"\"\n",
    "        One of the two ALS steps. Solve for the latent vectors\n",
    "        specified by type.\n",
    "        \"\"\"\n",
    "        if type == 'user':\n",
    "            # Precompute\n",
    "            YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(YTY.shape[0]) * _lambda\n",
    "\n",
    "            for u in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[u, :] = solve((YTY + lambdaI), \n",
    "                                             ratings[u, :].dot(fixed_vecs))\n",
    "        elif type == 'item':\n",
    "            # Precompute\n",
    "            XTX = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(XTX.shape[0]) * _lambda\n",
    "            \n",
    "            for i in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[i, :] = solve((XTX + lambdaI), \n",
    "                                             ratings[:, i].T.dot(fixed_vecs))\n",
    "        return latent_vectors\n",
    "\n",
    "    def train(self, n_iter=10):\n",
    "        \"\"\" Train model for n_iter iterations from scratch.\"\"\"\n",
    "        # initialize latent vectors\n",
    "        self.user_vecs = np.random.random((self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.random((self.n_items, self.n_factors))\n",
    "        \n",
    "        self.partial_train(n_iter)\n",
    "    \n",
    "    def partial_train(self, n_iter):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations. Can be \n",
    "        called multiple times for further training.\n",
    "        \"\"\"\n",
    "        ctr = 1\n",
    "        while ctr <= n_iter:\n",
    "            if ctr % 10 == 0 and self._v:\n",
    "                print ('\\tcurrent iteration: {}'.format(ctr))\n",
    "            self.user_vecs = self.als_step(self.user_vecs, \n",
    "                                           self.item_vecs, \n",
    "                                           self.ratings, \n",
    "                                           self.user_reg, \n",
    "                                           type='user')\n",
    "            self.item_vecs = self.als_step(self.item_vecs, \n",
    "                                           self.user_vecs, \n",
    "                                           self.ratings, \n",
    "                                           self.item_reg, \n",
    "                                           type='item')\n",
    "            ctr += 1\n",
    "    \n",
    "    def predict_all(self):\n",
    "        \"\"\" Predict ratings for every user and item. \"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0], \n",
    "                                self.item_vecs.shape[0]))\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            for i in range(self.item_vecs.shape[0]):\n",
    "                predictions[u, i] = self.predict(u, i)\n",
    "                \n",
    "        return predictions\n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction. \"\"\"\n",
    "        return self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "    \n",
    "    def calculate_learning_curve(self, iter_array, test):\n",
    "        \"\"\"\n",
    "        Keep track of MSE as a function of training iterations.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        iter_array : (list)\n",
    "            List of numbers of iterations to train for each step of \n",
    "            the learning curve. e.g. [1, 5, 10, 20]\n",
    "        test : (2D ndarray)\n",
    "            Testing dataset (assumed to be user x item).\n",
    "        \n",
    "        The function creates two new class attributes:\n",
    "        \n",
    "        train_mse : (list)\n",
    "            Training data MSE values for each value of iter_array\n",
    "        test_mse : (list)\n",
    "            Test data MSE values for each value of iter_array\n",
    "        \"\"\"\n",
    "        iter_array.sort()\n",
    "        self.train_mse =[]\n",
    "        self.test_mse = []\n",
    "        iter_diff = 0\n",
    "        for (i, n_iter) in enumerate(iter_array):\n",
    "            if self._v:\n",
    "                print ('Iteration: {}'.format(n_iter))\n",
    "            if i == 0:\n",
    "                self.train(n_iter - iter_diff)\n",
    "            else:\n",
    "                self.partial_train(n_iter - iter_diff)\n",
    "\n",
    "            predictions = self.predict_all()\n",
    "\n",
    "            self.train_mse += [get_mse(predictions, self.ratings)]\n",
    "            self.test_mse += [get_mse(predictions, test)]\n",
    "            if self._v:\n",
    "                print ('Train mse: ' + str(self.train_mse[-1]))\n",
    "                print ('Test mse: ' + str(self.test_mse[-1]))\n",
    "            iter_diff = n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpzDfHY8l2YJ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0fc2498176ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m MF_ALS = ExplicitMF(train_df_log, n_factors=30, \\\n\u001b[0m\u001b[0;32m      2\u001b[0m                     user_reg=0.1, item_reg=0.1)\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0miter_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mMF_ALS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_learning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df_log' is not defined"
     ]
    }
   ],
   "source": [
    "MF_ALS = ExplicitMF(train_df_log, n_factors=30, \\\n",
    "                    user_reg=0.1, item_reg=0.1)\n",
    "\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 100]\n",
    "MF_ALS.calculate_learning_curve(iter_array, test_df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXW3u7y0W2ow"
   },
   "outputs": [],
   "source": [
    "MF_ALS = ExplicitMF(train, n_factors=30, \\\n",
    "                    user_reg=0.1, item_reg=0.1)\n",
    "\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 100]\n",
    "MF_ALS.calculate_learning_curve(iter_array, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "I_41PIOgl_SD",
    "outputId": "d2a4de2c-380a-4945-ce4f-e44182f52d11"
   },
   "outputs": [],
   "source": [
    "#mse of ALS method \n",
    "als_pred = MF_ALS.predict_all()\n",
    "als_pred = np.exp(als_pred)\n",
    "print(als_pred.min())\n",
    "print(als_pred.max())\n",
    "print(\"mse of ALS method: \", get_mse(als_pred, test)) # it is better than SGD method :o \n",
    "print((np.exp(train)).max(), (np.exp(train)).min())\n",
    "print((np.exp(test)).max(), (np.exp(test)).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "Y2kJUaZ6mzGr",
    "outputId": "199cb7ee-ecee-46fe-9bfc-3b735d3d184d"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(iter_array, MF_ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-F3wLAvnfwO"
   },
   "outputs": [],
   "source": [
    "# my code to process the training data to have at least 1 entry in each row or column\n",
    "train_df = pd.read_csv(\"../data/input/CC2020_train_final.csv\")\n",
    "# test_df = pd.read_csv(\"CC2020_test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "CRN7Df6XKjFi",
    "outputId": "895b8f65-88f3-42ae-ffda-1a0b9c244342"
   },
   "outputs": [],
   "source": [
    "a = np.array([0,0,0])\n",
    "a.nonzero()[0]\n",
    "np.random.choice(a.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "7bUAayrsHJZN",
    "outputId": "cb58ad63-d8d6-4af9-bf3f-4414bb439580"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[['INBRED', 'TESTER', 'YIELD']]\n",
    "grouped_df = train_df.groupby(['INBRED','TESTER'], as_index=False).mean()\n",
    "grouped_df['YIELD'] = np.log(grouped_df['YIELD']).values\n",
    "train_df = grouped_df\n",
    "def train_test_split(mat):\n",
    "    test = np.zeros(mat.shape)\n",
    "    train = mat.copy()\n",
    "    for inbred in range(mat.shape[0]):\n",
    "        test_yields = np.random.choice(mat[inbred, :].nonzero()[0], \n",
    "                                        size=max(1, len(mat[inbred, :].nonzero()[0])//10), \n",
    "                                        replace=False)\n",
    "        train[inbred, test_yields] = 0.\n",
    "        test[inbred, test_yields] = mat[inbred, test_yields]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test\n",
    "inbred_index = {}\n",
    "tester_index = {}\n",
    "i = 0\n",
    "j = 0\n",
    "for idx, row in train_df.iterrows():\n",
    "    if row['INBRED'] not in inbred_index:\n",
    "        inbred_index[row['INBRED']] = i\n",
    "        i += 1\n",
    "    if row['TESTER'] not in tester_index:\n",
    "        tester_index[row['TESTER']] = j\n",
    "        j += 1\n",
    "print(len(inbred_index))\n",
    "print(len(tester_index))\n",
    "print(i)\n",
    "print(j)\n",
    "n_inbred = 593\n",
    "n_tester = 496\n",
    "mat = np.zeros((n_inbred, n_tester))\n",
    "for row in train_df.itertuples():\n",
    "    mat[inbred_index[row[1]], tester_index[row[2]]] = row[3]\n",
    "mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xd7RWAzpMZqu"
   },
   "outputs": [],
   "source": [
    "def train_test_split(mat):\n",
    "    test = np.zeros(mat.shape)\n",
    "    train = mat.copy()\n",
    "    for inbred in range(mat.shape[0]):\n",
    "        if (mat[inbred, :].sum() == 0): print(\"row is zero\")\n",
    "        # print(mat[inbred, :].sum())\n",
    "        test_yields = np.random.choice(mat[inbred, :].nonzero()[0], \n",
    "                                        size=max(0, len(mat[inbred, :].nonzero()[0])//10), \n",
    "                                        replace=False)\n",
    "        train[inbred, test_yields] = 0.\n",
    "        test[inbred, test_yields] = mat[inbred, test_yields]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8uCV6ZqXHppH"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nxk38opVHuei"
   },
   "outputs": [],
   "source": [
    "mat_na = np.zeros(mat.shape)\n",
    "for i in range(len(mat)):\n",
    "    for j in range(len(mat[0])):\n",
    "        if mat[i,j] == 0:\n",
    "            mat_na[i,j] = np.nan\n",
    "        else:\n",
    "            mat_na[i,j] = mat[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "_NuGb9N_H7h-",
    "outputId": "2c19410f-9ec0-4345-f85d-827e9c4fc2b7"
   },
   "outputs": [],
   "source": [
    "mat_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-JYZ6h6I5v2"
   },
   "outputs": [],
   "source": [
    "train_na = np.zeros(train.shape)\n",
    "for i in range(len(train)):\n",
    "    for j in range(len(train[0])):\n",
    "        if train[i,j] == 0:\n",
    "            train_na[i,j] = np.nan\n",
    "        else:\n",
    "            train_na[i,j] = train[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UH9eD5qTJP5F",
    "outputId": "ca31fb58-e59b-48a0-d4ae-5c2dd79bbfb3"
   },
   "outputs": [],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "KTvuJZ5_LDpm",
    "outputId": "ab16a26e-980e-4f76-94ae-ed004fb450fa"
   },
   "outputs": [],
   "source": [
    "np.isnan(train_na[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wCh6pVnNTjL"
   },
   "outputs": [],
   "source": [
    "for i in range(train.shape[0]):\n",
    "    if train[i,:].sum() == 0:\n",
    "        print(\"row is zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJblBq-ATJCp"
   },
   "outputs": [],
   "source": [
    "for i in range(mat.shape[0]):\n",
    "    if mat[i,:].sum() == 0:\n",
    "        print(\"row is zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uOsXtBzATbPv"
   },
   "outputs": [],
   "source": [
    "#https://gist.github.com/kastnerkyle/9341182\n",
    "\n",
    "# (C) Kyle Kastner, June 2014\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def minibatch_indices(X, minibatch_size):\n",
    "    X = list(X)\n",
    "    minibatch_indices = np.arange(0, len(X), minibatch_size)\n",
    "    minibatch_indices = np.asarray(list(minibatch_indices) + [len(X)])\n",
    "    start_indices = minibatch_indices[:-1]\n",
    "    end_indices = minibatch_indices[1:]\n",
    "    return zip(start_indices, end_indices)\n",
    "\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    \"\"\"\n",
    "    http://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "    \"\"\"\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "\n",
    "def PMF(X, rank=10, learning_rate=0.001, momentum=0.8,\n",
    "        regularization=0.25, minibatch_size=1000, max_epoch=1000,\n",
    "        nan_value=0, status_percentage=0.1, random_state=None):\n",
    "    \"\"\"\n",
    "    Python implementation of Probabilistic Matrix Factorization (PMF).\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: numpy array or scipy.sparse coo matrix, shape (n_users, n_items)\n",
    "        Input data. If a dense array is passed in, it will be converted to a\n",
    "        sparse matrix by looking for all `nan_value` numbers and treating them\n",
    "        as empty.\n",
    "    rank: int, optional (default=10)\n",
    "       Rank of the low-rank factor matrices. A higher rank should result in a\n",
    "       better approximation, at the cost of more memory and slower computataion.\n",
    "    learning_rate: float, optional (default=0.001)\n",
    "        Learning rate for minibatch gradient descent.\n",
    "    momentum: float, optional (default=0.8)\n",
    "        Momentum for minibatch gradient descent.\n",
    "    regularization: float, optional (default=0.25)\n",
    "        L2 regularization penalty for minibatch gradient descent.\n",
    "    minibatch_size: int, optional (default=1000)\n",
    "       The size of each minibatch. If this is larger than size of the dataset,\n",
    "       will default to running over the whole dataset.\n",
    "    max_epoch: int, optional (default=1000)\n",
    "        The maximum number of epochs.\n",
    "    nan_value: int, optional (default=0)\n",
    "        This value will be masked out of the input for calculations\n",
    "        Should match the value considered the \"not rated\" in the dataset X.\n",
    "    status_percentage: float in (0, 1), optional (default=0.1)\n",
    "        The relative percentage of `max_epochs` when status will be printed.\n",
    "        For example, 0.1 is every 10%, 0.01 is every 1%, and so on. For\n",
    "        the default values of max_epoch=1000, status_percentage=0.1 this\n",
    "        is equivalent to a status print every 100 epochs.\n",
    "    random_state: RandomState, int, or None, optional (default=None)\n",
    "        Random state to pass in. Can be an int, None, or np.random.RandomState\n",
    "        object.\n",
    "    Returns\n",
    "    -------\n",
    "    U: array-like, shape (X.shape[0], rank)\n",
    "        Row basis for reconstruction.\n",
    "        Usage:\n",
    "        reconstruction = np.dot(U, V.T) + X_mean\n",
    "    V: array-like, shape (X.shape[1], rank)\n",
    "        Column basis for reconstruction.\n",
    "        Usage:\n",
    "        reconstruction = np.dot(U, V.T) + X_mean\n",
    "    X_mean: float\n",
    "        Global mean prediction, needed for reconstruction\n",
    "        Usage\n",
    "        reconstruction = np.dot(U, V.T) + X_mean\n",
    "    Notes\n",
    "    -----\n",
    "    Based on code from Ruslan Salakhutdinov\n",
    "    http://www.cs.toronto.edu/~rsalakhu/code_BPMF/pmf.m\n",
    "    Probabilistic Matrix Factorization, R. Salakhutdinov and A. Mnih,\n",
    "    Advances in Neural Information Processing Systems 20, 2008\n",
    "    \"\"\"\n",
    "    if not sparse.isspmatrix_coo(X):\n",
    "        val_index = np.where(X != nan_value)\n",
    "        X = sparse.coo_matrix((X[val_index[0], val_index[1]],\n",
    "                               (val_index[0], val_index[1])))\n",
    "    # Simplest prediction is the global mean\n",
    "    X_mean = X.mean()\n",
    "    lr = learning_rate\n",
    "    reg = regularization\n",
    "    mom = momentum\n",
    "    if random_state is None or type(random_state) is int:\n",
    "        random_state = np.random.RandomState(random_state)\n",
    "    N, M = X.shape\n",
    "    U = 0.1 * random_state.randn(N, rank)\n",
    "    V = 0.1 * random_state.randn(M, rank)\n",
    "    U_inc = np.zeros_like(U)\n",
    "    V_inc = np.zeros_like(V)\n",
    "    dU = np.zeros_like(U)\n",
    "    dV = np.zeros_like(V)\n",
    "    epoch = 0\n",
    "    status_inc = int(np.ceil(max_epoch * status_percentage))\n",
    "    print(\"Printing updates every %i epochs\" % status_inc)\n",
    "    status_points = list(range(0, max_epoch, status_inc)) + [max_epoch - 1]\n",
    "    # Need this in order to index\n",
    "    X_s = X.tolil()\n",
    "    while epoch < max_epoch:\n",
    "        # Get indices for non-NaN values\n",
    "        r, c = X.nonzero()\n",
    "        mb_indices = minibatch_indices(zip(r, c), minibatch_size)\n",
    "        mb_indices = list(mb_indices)\n",
    "        n_batches = len(mb_indices)\n",
    "        shuffle_in_unison(r, c)\n",
    "        mean_abs_err = 0.\n",
    "        for i, j in mb_indices:\n",
    "            # Reset derivative matrices each minibatch\n",
    "            dU[:, :] = 0.\n",
    "            dV[:, :] = 0.\n",
    "            # Slice out row and column indices\n",
    "            r_i = r[i:j]\n",
    "            c_i = c[i:j]\n",
    "            # Get data corresponding to the row and column indices\n",
    "            X_i = X_s[r_i, c_i].toarray().ravel() - X_mean\n",
    "            # Compute predictions\n",
    "            pred = np.sum(U[r_i] * V[c_i], axis=1)\n",
    "            # Compute how algorithm is doing\n",
    "            mean_abs_err += np.sum(np.abs(pred - X_i)) / (n_batches * (j - i))\n",
    "            # Loss has a tendency to be unstable, but is the \"right thing\"\n",
    "            # to monitor instead of sum_abs_err\n",
    "            # pred_loss = (pred - X_i) ** 2\n",
    "            # Compute gradients\n",
    "            grad_loss = 2 * (pred - X_i)\n",
    "            grad_U = grad_loss[:, None] * V[c_i] + reg * U[r_i]\n",
    "            grad_V = grad_loss[:, None] * U[r_i] + reg * V[c_i]\n",
    "            dU[r_i] = grad_U\n",
    "            dV[c_i] = grad_V\n",
    "            # Momentum storage\n",
    "            U_inc = mom * U_inc + lr * dU\n",
    "            V_inc = mom * V_inc + lr * dV\n",
    "            U -= U_inc\n",
    "            V -= V_inc\n",
    "        if epoch in status_points:\n",
    "            print(\"Epoch %i of %i\" % (epoch + 1, max_epoch))\n",
    "            print(\"Mean absolute error %f\" % (mean_abs_err))\n",
    "        epoch += 1\n",
    "    return U, V, X_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "joVcbrawLwnU",
    "outputId": "73882ce4-1f97-4609-85e5-aab7e75686b7"
   },
   "outputs": [],
   "source": [
    "R = np.array([[5, 3, 0, 1],\n",
    "                [4, 0, 0, 1],\n",
    "                [1, 1, 0, 5],\n",
    "                [1, 0, 0, 4],\n",
    "                [0, 1, 5, 4]], dtype=float)\n",
    "U, V, m = PMF(R, learning_rate=0.001, momentum=0.95,\\\n",
    "                minibatch_size=2, rank=5, max_epoch=250, random_state=1999)\n",
    "R2 = np.dot(U, V.T) + m\n",
    "plt.matshow(R * (R > 0))\n",
    "plt.title(\"Ground truth ratings\")\n",
    "plt.matshow(R2 * (R > 0))\n",
    "plt.title(\"Predicted ratings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "BnLPOYYvMJ50",
    "outputId": "6e9240c0-0cae-4aa7-ff64-b5c9452688f2"
   },
   "outputs": [],
   "source": [
    "U, V, m = PMF(train, learning_rate=0.001, momentum=0.95,\\\n",
    "                minibatch_size=5, rank=30, max_epoch=250, random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hu5J9e9nNPv6"
   },
   "outputs": [],
   "source": [
    "pred = np.dot(U, V.T) + m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z3CaSBfJNYM6",
    "outputId": "94733f26-3ab6-4f8e-afa8-29165876947c"
   },
   "outputs": [],
   "source": [
    "get_mse(np.exp(pred), np.exp(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "2l9P4Q0SNfkQ",
    "outputId": "c5ef43e1-cd33-4e74-e078-d39743303e5f"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.exp(pred)[train.nonzero()].flatten(), alpha = 0.5, label = \"test prediction\")\n",
    "plt.title(\"Histogram of Test Prediction vs Test Data\")\n",
    "plt.hist(np.exp(train)[train.nonzero()].flatten(), alpha = 0.5, label = \"test data\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "4Rk5sK32PgNR",
    "outputId": "0a6bc1c4-3141-4aa5-acfa-1ea6a1e48d10"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.exp(pred).flatten(), alpha = 0.5, label = \"test prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "SwqhC1BxPraw",
    "outputId": "e6639a2c-56f9-42a1-b2b0-33833cbf0c61"
   },
   "outputs": [],
   "source": [
    "np.exp(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5sjuGZfIPNzP",
    "outputId": "cf9cd191-19ff-408c-f1ea-f446822ced78"
   },
   "outputs": [],
   "source": [
    "np.exp(pred).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JjtO3xL7PUlE",
    "outputId": "1f2c7691-196d-4095-c2b0-b325b4ce7058"
   },
   "outputs": [],
   "source": [
    "np.exp(pred).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1E4DlpKWNhQp"
   },
   "outputs": [],
   "source": [
    "#explore this for graph auto encoder\n",
    "#https://github.com/tkipf/gae"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "syngenta_data_exploration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
